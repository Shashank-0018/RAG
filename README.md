# Bheeshma

## The RAG System

A lightweight Retrieval-Augmented Generation (RAG) pipeline built in Node.js, integrating local BERT embeddings, ChromaDB as the vector store, and Groq LLM for fast, context-aware responses.
Designed for free, local, and small-scale document intelligence â€” perfect for projects like NCERT-based Q&A or PDF knowledge assistants.

## TECH

| Component              | Tool / Library                                     |
| ---------------------- | -------------------------------------------------- |
| **Language**           | Node.js                                            |
| **Embeddings**         | BERT (`all-MiniLM-L6-v2` via SentenceTransformers) |
| **Vector Database**    | ChromaDB (Local)                                   |
| **LLM**                | Groq SDK                                           |
| **PDF Parsing**        | pdf-parse                                          |
| **Integration Bridge** | Python â†” Node.js (for BERT)                        |

## Features

- ðŸ“‚ Local document ingestion (PDFs, text files)
- ðŸ§  Contextual semantic search using BERT embeddings
- ðŸ’¾ Vector-based similarity retrieval with ChromaDB
- âš¡ LLM-powered answers via Groq SDK
- ðŸ”’ 100% local + free (no API costs for embeddings)
- ðŸ§© Modular code architecture for scaling

## Author

Shashank Asthana (Asthanaji)
ðŸ’» [GitHub](https://github.com/Shashank-0018/RAG) | ðŸ”— [LinkedIn](https://www.linkedin.com/in/shashank-asthanaji/)
